<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Inteligencia Artificial Basico</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="../../css/estilos.css">
</head>
    <body>
        <div class="container">
    <div class="slide">
        <h2>Simulación y Prosumidor (Lección 7)</h2>
        <p>Conceptos clave sobre la simulación y el rol del prosumidor en el análisis de datos y modelos de IA.</p>
    </div>

    <div class="slide">
        <h2>Evaluación y Ajuste de Modelos</h2>
        <h3>Métricas de Evaluación:</h3>
        <ul>
            <li>Precisión, recall, F1-score para clasificación.</li>
            <li>Mean Squared Error (MSE), R-squared para regresión.</li>
        </ul>
    </div>

    <div class="slide">
        <h2>Precisión, Recall y F1-score</h2>
        <p>Son métricas de evaluación para modelos de clasificación.</p>
        <pre>
from sklearn.metrics import precision_score, recall_score, f1_score

# Valores reales (ground truth) y predicciones del modelo
y_true = [0, 1, 1, 1, 0, 1, 0]
y_pred = [0, 1, 1, 0, 0, 1, 1]

# Calcular la precisión, recall y F1-score
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

# Imprimir los resultados
print("Precisión:", precision)
print("Recall:", recall)
print("F1-score:", f1)
        </pre>
    </div>
    
    <div class="slide">
        <h2>Mean Squared Error (MSE)</h2>
        <p>El MSE mide el error cuadrático medio en problemas de regresión.</p>
        <pre>
from sklearn.metrics import mean_squared_error

# Valores reales y predicciones del modelo
y_true = [3.0, -0.5, 2.0, 7.0]
y_pred = [2.5, 0.0, 2.1, 7.8]

# Calcular el MSE
mse = mean_squared_error(y_true, y_pred)

# Imprimir el resultado
print("MSE:", mse)
        </pre>
    </div>
    
    <div class="slide">
        <h2>R-squared (R²)</h2>
        <p>El coeficiente de determinación indica qué tan bien el modelo explica la variabilidad de los datos.</p>
        <pre>
from sklearn.metrics import r2_score

# Valores reales y predicciones del modelo
y_true = [3.0, -0.5, 2.0, 7.0]
y_pred = [2.5, 0.0, 2.1, 7.8]

# Calcular el coeficiente R²
r2 = r2_score(y_true, y_pred)

# Imprimir el resultado
print("R-squared:", r2)
        </pre>
    </div>
    
    <div class="slide">
        <h2>Ajuste de Hiperparámetros</h2>
        <h3>Búsqueda de Hiperparámetros Óptimos:</h3>
        <pre><code>
from sklearn.model_selection import GridSearchCV
param_grid = {'n_neighbors': range(1, 11)}
grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
grid.fit(X, y)
print(f'Best parameters: {grid.best_params_}')
print(f'Best cross-validation score: {grid.best_score_}')
        </code></pre>
    </div>

    <div class="slide">
        <h2>Documentación y Presentación de Resultados</h2>
        <p>Redacción de un informe detallado sobre la implementación, evaluación y ajuste de los modelos.</p>
        <pre><code>
import seaborn as sns
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.show()
        </code></pre>
    </div>
    
    <div class="slide">
        <h2>Desarrollo de un Pequeño Proyecto de IA</h2>
        <h3>Selección y Definición del Proyecto:</h3>
        <p>Ejemplo: Clasificación de correos electrónicos como spam o no spam.</p>
        <pre><code>
import pandas as pd
data = pd.read_csv('emails.csv')
print(data.head())
        </code></pre>
    </div>

    <div class="slide">
        <h2>Implementación del Modelo de Clasificación</h2>
        <h3>Preprocesamiento de Datos:</h3>
        <pre><code>
import re
from nltk.corpus import stopwords

def preprocess_text(text):
    text = re.sub(r'\W', ' ', text)
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    return text

data['text'] = data['text'].apply(preprocess_text)
        </code></pre>
    </div>

    <div class="slide">
        <h2>Entrenamiento del Modelo</h2>
        <pre><code>
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data['text'])
y = data['spam']
        </code></pre>
    </div>
    
    <div class="slide">
        <h2>Evaluación del Modelo</h2>
        <pre><code>
y_pred = model.predict(X_test)
from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, y_pred))
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
        </code></pre>
    </div>

    <div class="slide">
        <h2>Visualización y Documentación</h2>
        <pre><code>
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(model, X_test, y_test)
plt.show()
        </code></pre>
    </div>
    
    <div class="slide">
        <h2>Presentación de Resultados</h2>
        <p>Presentación del problema, metodología y resultados.</p>
        <ul>
            <li>Diapositivas con gráficos y tablas.</li>
            <li>Código fuente documentado.</li>
        </ul>
    </div>

        <div class="nav">
            <button onclick="prevSlide()">Anterior</button>
            <button onclick="nextSlide()">Siguiente</button>
        </div>
    </div>
    <script src="../../js/slide.js"></script>
    </body>
</html>
