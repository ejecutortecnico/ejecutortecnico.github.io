<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JavaScript</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="../../css/estilos.css">
</head>
    <body>
        <div class="container">
            <div class="slide">
  <h1>MISIÓN 1 · Lección 3</h1>
  <h2>Desarrollo de Aplicaciones de Análisis de Texto</h2>
  <p>En esta lección aprenderemos cómo transformar un modelo de análisis de texto en una aplicación funcional que pueda ser consumida por usuarios o integrarse en otros sistemas.</p>
</div>

<div class="slide">
  <h2>Arquitectura de una aplicación NLP</h2>
  <ol>
    <li><strong>Entrada:</strong> texto ingresado manualmente, archivos o datos de una API.</li>
    <li><strong>Pipeline NLP:</strong> preprocesamiento → vectorización → modelo de predicción.</li>
    <li><strong>Salida:</strong> etiquetas de sentimiento, puntuaciones, visualizaciones o endpoints de API.</li>
  </ol>
</div>

<div class="slide">
  <h2>Ejemplo: microservicio con FastAPI</h2>
  <pre><code class="language-python">from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Item(BaseModel):
    text: str

@app.post("/predict")
async def predict(item: Item):
    # Ejemplo: probabilidad fija
    proba = 0.87
    label = "positivo" if proba > 0.5 else "negativo"
    return {"label": label, "score": proba}
</code></pre>
  <p>Con FastAPI podemos crear un servicio que reciba texto y devuelva la predicción del modelo.</p>
</div>

<div class="slide">
  <h2>Conectar un modelo real</h2>
  <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# Entrenamiento del modelo
X = ["me encanta", "lo odio", "genial", "terrible"]
y = [1, 0, 1, 0]

pipe = Pipeline([
  ("tfidf", TfidfVectorizer()),
  ("clf", LogisticRegression(max_iter=1000))
])
pipe.fit(X, y)

# Endpoint con modelo real
@app.post("/predict_model")
async def predict_model(item: Item):
    label = pipe.predict([item.text])[0]
    proba = pipe.predict_proba([item.text])[0,1]
    return {"label": "positivo" if label == 1 else "negativo", "score": float(proba)}
</code></pre>
</div>

<div class="slide">
  <h2>Interfaz gráfica simple</h2>
  <p>Podemos usar <strong>Streamlit</strong> para crear una interfaz web rápida:</p>
  <pre><code class="language-python">import streamlit as st

st.title("Análisis de Sentimientos")
texto = st.text_area("Escribe un texto:")

if st.button("Analizar"):
    resultado = pipe.predict([texto])[0]
    st.write("Resultado:", "Positivo" if resultado == 1 else "Negativo")
</code></pre>
</div>

<div class="slide">
  <h2>Persistencia y monitoreo</h2>
  <ul>
    <li>Guardar predicciones y retroalimentación en una base de datos.</li>
    <li>Monitorear métricas en producción: latencia, precisión, drift de datos.</li>
    <li>Versionar modelos con herramientas como <strong>MLflow</strong>.</li>
  </ul>
</div>

<div class="slide">
  <h2>Buenas prácticas</h2>
  <ul>
    <li>Separar entrenamiento y predicción en servicios distintos.</li>
    <li>Documentar la API (FastAPI genera docs automáticamente en <code>/docs</code>).</li>
    <li>Automatizar despliegue con Docker y CI/CD.</li>
  </ul>
</div>

<div class="slide">
  <h2>Ejemplo de despliegue con Docker</h2>
  <pre><code class="language-dockerfile"># Dockerfile
FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
</code></pre>
  <p>Luego ejecutar: <code>docker build -t nlp-app .</code> y <code>docker run -p 8000:80 nlp-app</code></p>
</div>

<div class="slide">
  <h2>Aplicaciones reales</h2>
  <ul>
    <li>Chatbots con análisis de intención y emociones.</li>
    <li>Herramientas de análisis de reseñas de productos.</li>
    <li>Moderación automática de comentarios en redes sociales.</li>
  </ul>
</div>

<div class="slide">
  <h2>Reflexión final</h2>
  <p>Convertir modelos en aplicaciones es clave para crear valor real. Al integrar APIs, interfaces gráficas y monitoreo, aseguramos que el análisis de texto sea útil y escalable en entornos productivos.</p>
</div>

    

        <div class="nav">
            <button onclick="prevSlide()">Anterior</button>
            <button onclick="nextSlide()">Siguiente</button>
        </div>
    </div>
    <script src="../../js/slide.js"></script>
    </body>
</html>
v